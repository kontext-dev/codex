# Codex RS Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# OpenAI / LLM Configuration
# =============================================================================

# OpenAI API key for LLM calls (required for real benchmarks)
OPENAI_API_KEY=sk-xxx

# Alternative: Codex-specific API key (takes precedence if set)
# CODEX_API_KEY=sk-xxx

# Model selection (optional, defaults shown)
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_SUBLM_MODEL=gpt-4o-mini

# =============================================================================
# Kontext Gateway Configuration
# =============================================================================

# OAuth client credentials for Kontext Gateway
KONTEXT_CLIENT_ID=your-client-id
KONTEXT_CLIENT_SECRET=your-client-secret

# MCP endpoint URL (default: https://gateway.kontext.dev/mcp)
KONTEXT_MCP_URL=https://gateway.kontext.dev/mcp

# OAuth token URL (default: https://gateway.kontext.dev/oauth2/token)
KONTEXT_TOKEN_URL=https://gateway.kontext.dev/oauth2/token

# =============================================================================
# RLM Configuration (optional overrides)
# =============================================================================

# Maximum total tokens across all LLM calls
# RLM_MAX_TOTAL_TOKENS=500000

# Maximum recursion depth for sub-LM calls
# RLM_MAX_RECURSION_DEPTH=5

# Per sub-LM call token limit
# RLM_PER_CALL_LIMIT=50000

# =============================================================================
# Testing Configuration
# =============================================================================

# Enable verbose test output
# RUST_LOG=debug

# Skip integration tests requiring credentials
# SKIP_INTEGRATION_TESTS=1
